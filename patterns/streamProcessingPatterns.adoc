ifndef::imagesdir[:imagesdir: ./images]

= Stream-Processing Patterns

A *stream* can be defined as a continuous sequence of events ordered by time. +
All events in a stream have a common message format and structure.

*Stream processing* is performing operations on events in motion. It can be as simple as a stateless service consuming events and transforming its event format, or as complex as storing and processing stateful data in memory with low latency and reliability.

== Streaming Data Processing Patterns

=== Transformation Pattern

* maps the data of one event to another

* Message transformation
 ** custom or Apache Camel, KSQL, Amazon Kinesis, and Azure Stream Analytics

* Protocol switching

=== Filters and Thresholds Pattern

* useful for extracting only the relevant events we need.

Usage:

* Filter events by category
* Apply a threshold for alerting


=== Windowed Aggregation Pattern

* enables us to analyze a collection of events based on a condition

* These windows can be based on the time or event count, such as the last five minutes or the last 100 events. These windows may also have behaviors such as sliding or batching, defining when events are added and removed from the window.

Types: length sliding, length batch, time sliding, and time batch

* The Windowed Aggregation pattern is *stateful*, meaning it stores data related to the events in memory.

Usage:

* Aggregate events over time
* Aggregate events over length

Because windows are collections of events, the most effective way of scaling them is by sharding.

Splitting the incoming events into different windows, aggregating the events in isolation, and then using the Stream Join pattern to build bigger aggregations.

Libraries: Esper or Siddhi

image::windowAgg.png[Window Aggregation]

=== Stream Join Pattern

* enables us to join events from multiple streams with different schemas.

* defining a condition to identify the joining events.
*  define a buffer that determines how long events should wait for corresponding events to arrive from other event streams (window)

* The Stream Join pattern is *stateful*, as it buffers events for the join

Usage:

* Scatter and gather - process the same event in parallel, performing different operations, and finally combine the results so all event outputs can be emitted as a single event

* Join various types of events -

=== Temporal Event Ordering Pattern

* tries to detect various interesting complex event occurrences by identifying patterns based on event arrival order.

Example: We detect a continuous stock price increase followed by a single drop, and the user will be notified as soon as the first drop is detected.

A new state machine instance should be initiated upon each event arrival that triggers the initial state of the state machine.

Usage:

* Detect sequence of event occurrence - for identifying an incident by having a sequence of events happen in a prescribed order. (transaction identifying fraud)

* Detect nonoccurrence of event

Stream processing systems like Azure Streaming Analytics, Apache Spark, Apache Flink, Esper, and Siddhi are some that can provide this functionality by default.

=== Machine Learner Pattern

* Prebuilt machine learning models

Machine learning frameworks such as Apache Spark, TensorFlow, or even Python

* Online machine learning models

These are models that tune themselves based on the information they receive as they produce predictions.

=== Summary
|===
|Pattern	|When to use	|When not to use	Benefits
|Transformation
|To transform the event format, structure, or protocol. +
To add or remove partial data to or from the event. +
Third-party systems do not support the current event.
|The consuming system has the ability to understand the event.
|Allows incompatible systems to communicate with one another. +
Reduces event size by containing only relevant information.

|Filters and Thresholds
|Only a subset of events is relevant for processing.
|All events are needed for decision making.
|Reduces the load on the system by selecting only events that can produce the most value to the use case.

|Windowed Aggregation
|To aggregate events over time or length.
To perform operations such as summation, minimum, maximum, average, standard deviation, and count on the events.
|For operations that cannot be performed with fixed memory such as detecting the median of the events. +
High accuracy is needed without the use of reliability patterns.
|Reduces the load on the system by aggregating events. +
Provides data summary to better understand the behavior as a whole. +

|Stream Join
|To join events from two or more event streams. +
To collect events that were previously split to parallelize processing.
|Joining events do not arrive in relatively close proximity. +
High accuracy is needed without the use of reliability patterns.
|Allows events to be correlated. +
Enables synchronous processing of events.

|Temporal Event Ordering
|To detect the sequence of event occurrences. +
To detect the nonoccurrence of events.
|Event sequencing cannot be defined as a finite-state machine. +
High accuracy is needed without the use of reliability patterns. +
Incoming events arrive out-of-order.
|Allows detecting complex conditions based on event arrival order.

|Machine Learner
|To perform predictions in real time. +
To perform classification, clustering, or regression analysis on the events.
|We cannot use a model to accurately predict the values. +
Historical data is not available for building machine learning models.
|Automates decision making. +
Provides reasonable estimates.
|===

== Scaling and Performance Optimization Patterns

=== Sequential Convoy Pattern

* separating events into various categories and processing them in parallel. It also works to persist event ordering so events can be combined at a later time, while preserving the original order of the events.

Each event also can be labeled with a sequence number before separation. +
This sequencing can also be used to join the parallel streams together at a later time, based on the original event order. We use a merge sort by selecting the smallest sequence number among all the substreams

Usage:

* Scale stream-processing applications - use a simple round-robin strategy to distribute events to multiple substreams, which will process events much faster.

** separate events into different substreams based on hash values of customer IDs. This will process all events belonging to the same customer ID on the same node, improving the chance of cache hits. By reducing the number of customer IDs processed by a single microservice, we further increase cache hits, thereby meeting our performance goals.

image::seqConvoy.png[Sequential convoy]

* Partition the stream processing

    ** The Sequential Convoy pattern enables us to execute different use cases against the same event stream by partitioning different event types into parallel streams.

A better approach to regrouping events is an *end-of-sequence message*. This can be emitted by the processing applications with the last process message ID in a periodic time interval. This tells us that all IDs before the given end-of-sequence ID have been processed by the upstream applications and that the missing IDs smaller than the last ID are dropped messages. This unblocks the processing of later events.

When grouping based on sequence numbers is not possible, we can simply collect events and publish them to a single topic, and then use the Buffered Event Ordering pattern, to buffer and sort events based on sequence numbers or event timestamps.

=== Buffered Event Ordering Pattern

* allows us to reorder events before processing them downstream. We can order events based on time or on the order they are generated.

* Sequence numbers will continuously increase, and we can guarantee that each event in a stream will have a unique number. But with a timestamp, we cannot guarantee that all events will have unique values, because multiple events can be generated in the same millisecond.

If next event is not next in order:

* wait with a timeout for the event
* the previous processor can send an empty event with sequence number

Usage:

* Order events generated on distributed event sources

The out-of-order events can be sent to a single topic in a message broker, and by using a microservice, those events can be fetched, reordered through the Buffered Event Ordering pattern, and sent downstream for further processing.

* Reorder events generated from the same event sources

* needs to store some events in the buffer while it is waiting for older events to arrive; this means that the microservice has state

=== Course Correction Pattern

* Update results with new

This pattern is commonly used when users are eager to obtain aggregated results quickly. This can especially be useful when we are displaying results in real time on a screen.

* Correct previous decisions

Sometimes we need to make an early decision, and when the situation changes, we send compensation events so that corrective actions can be taken.
(multiple offers accepted - select only one send reject events to the others)

=== Watermark pattern

* useful for periodically aligning stream processing across multiple microservices

* determine whether all microservices have processed all arrived events before a given event, which is commonly referred to as the *watermark event*.

Steps:

*  a watermark generator should generate a watermark event periodically and send it through all the external inputs

*  microservices should pass it through to their dependent systems

* each intermediate microservice that consumes this event can resend it in the same position among the sequence of events

Systems independently generate the watermark events at given intervals, such as once every minute or every five minutes

* When the microservice receives a watermark event in a stream:
 ** it should not continue processing any more events from that stream
 ** process only events from other streams that have not yet received the corresponding watermark event
 ** When we receive all corresponding watermark events on all streams, we can pass that watermark event to all its dependents and continue processing other events from all the input streams until we receive the next watermark event in a stream.

This process is repeated, and this approach ensures that event processing is synchronized at each watermark event.

Usage:

* Synchronize events generated from event sources that are time synchronized

Watermarks can be used to generate synchronized event groups that can produce accurate aggregation results.

image::watermark.png[Watermark]

* Synchronize events generated from nonsynchronized sources

To enforce synchronization, each sensor client can periodically fetch a sequence number from the global counter deployed on a central server and inject it along with the sensor reading.

image::watermark2.png[Watermark]

=== Summary

|===
|Pattern	|When to use	|When not to use	Benefits
|Sequential Convoy
|To scale stream-processing applications.+
To partition streams so each stream can be used for various use cases. +
To allow processing events in parallel and regroup them based on the original order. +	Streaming applications have enough capacity to process the events.
|Supports scalability of stream processing +
Preserves event ordering when events are processed in parallel.

|Buffered Event Ordering
To order events based on timestamp or sequence number. +
To order events that are already out of order and published via a single event stream.
|To group events from multiple ordered event streams. +
True ordering of events that are generated from distributed sources. +
Reliability patterns cannot be applied to the application.
|Can be applied in front of any application that needs events in order.

|Course Correction
|To correct previously produced results. +
To produce early aggregation estimates. +
To guess the event-sequence order and correct the decision later.
|The dependent downstream applications cannot handle continuous event updates.
|Allows us to produce early estimates and correct them as we have more data.

|Watermark
|To perform aggregation operations on event streams that are out of sync. +
Try to order events that are generated by distributed systems.
|We cannot inject watermark events closer to the event sources. +
Intermediate systems cannot bypass watermark events. +
Network bandwidth is a concern. +
|Periodically synchronizes events across multiple streams. +
Helps overcome network and processing latency added by intermediate systems.
|===

== Reliability Patterns

=== Replay Pattern

* the state of a microservice can be restored by replaying the events it has processed in the past, especially when its state depends only on recent events.

* When the stateful microservice can store its state periodically, we will be able to identify the last successfully processed event from the latest snapshot, and we should be able to replay all events arrived after that.

* delay sending acknowledgments to the queues until the microservice is done processing and cleaning out its state, or until it persists its state in durable storage.

* not use this pattern when duplicate events can cause confusion on the part of dependent systems.

=== Periodic Snapshot State Persistence Pattern

* persist the application state in a periodic manner so that we can restore the state reliably after system restarts or failures.

* makes a copy of its current state and persists that to a durable store between processing events

* When using a log-based message broker like Kafka, we should *store the event sequence number with the snapshot*

* If the dependent systems do not support duplicate events, we can also introduce a *new output sequence number* from the microservice. The dependent systems can detect that the same sequence is repeating and drop the duplicate events without reprocessing them. This will achieve exactly once event processing even across system failures.


=== Two-Node Failover Pattern

* running a parallel backup microservice. When microservices are deployed, they perform a leader election; we can use systems such as ZooKeeper or native cloud services to designate one microservice as primary and the other as secondary.

Steps:

* Both microservices consuming the same event are achieved by subscribing to a common topic
* Only the primary will be emitting the output to its dependencies, and it also sends the output to the secondary.
* The secondary matches its output against the primaryâ€™s and drops all events that have been processed by the primary
* if the primary fails, the secondary will be promoted to become the primary, and, while continuing to process events, it will also start publishing to the dependencies. Because it knows the last event published by the previous primary (Event B), it will be able to determine which events have not yet been sent and send those events (Event C) first before publishing new events (Event D).
* If the failed microservice is restarted in a later state, it is demoted to operating as the secondary, where it will consume events, process them, and drop them based on the outputs generated by the current primary.

image::twoFailover.png[Two Failover]

* This pattern is complex to implement, and the architectural complexity is not worthwhile if we can tolerate downtime during system failure.

* a risk of network partitioning between the primary and secondary exists. In this case, we require a third system to function as the leadership elector; otherwise, both microservices could become primary in parallel and send outputs downstream.

=== Summary

|===
|Pattern	|When to use	|When not to use	Benefits
|Replay
|The system state contains only recent events. +
To restore state only when there is access to the previously processed events. +
To process data from persistence stores, filesystems, and log-based message brokers. +
|We cannot guarantee that previously processed data cannot be accessed again. +
Dependent systems cannot process duplicate events. +
Systems cannot take time to re-create their state. +
The system state needs to contain events that span over a long period.
|Allows re-creating state without storing large snapshots.

|Periodic Snapshot State Persistence
|The system state needs to contain events that span over a long period. +
To restore state only when there is access to the previously processed events. +
To process data from persistence stores, filesystems, and log-based message brokers.
|The system state contains only recent events. +
We cannot guarantee that previously processed events can be accessed again. +
Systems cannot take time to re-create their state.
|Allows re-creating state faster. +
Supports larger and long-running system states. +
Supports dependent applications that cannot process duplicate events.

|Two-Node Failover
|We cannot take time to restore the application after failure. +
The system state needs to contain events that span over a long period. +
To restore state only when there is access to the previously processed events.
|We cannot guarantee that previously processed events can be accessed again. +
Systems can take time to re-create their state.
|Supports low-latency and highly available stream processing. +
Supports dependent applications that cannot process duplicate events.
|===

=== Technologies
|===
|Stream-processing technology	|When to use	|When not to use
|Esper
|To embed into cloud native applications. +
To support transformations, filtering and thresholds, windowed aggregations, joins, and temporal event ordering.
|To run as a standalone application. +
To run machine learning models. +
Built-in reliability is required.

|Siddhi
|To embed into cloud native applications. +
To run as a standalone cloud native application. +
To support transformations, filtering and thresholds, windowed aggregations, joins, temporal event ordering, and machine learning.
|High scalability is needed.

|ksqlDB
|Kafka is used in the infrastructure. +
To support transformations, filtering and thresholds, windowed aggregations, and joins. +
To build materialized views from the input events.
|Kafka is not used in the infrastructure. +
Temporal event ordering and machine learning is needed.

|Apache Spark
|Support for both stream and batch processing is needed. +
To support transformations, filtering and thresholds, windowed aggregations, joins, and machine learning.
|A lightweight system is needed for stream processing. +
Temporal event ordering is needed. +
To embed into cloud native applications.

|Apache Flink
|To support transformations, filtering and thresholds, windowed aggregations, joins, and temporal event ordering, along with graph processing. +
For high scalability and availability requirements.
|A lightweight system is needed for stream processing. +
To embed into cloud native applications.

|Amazon Kinesis
|To support Flink in AWS.  +
To support transformations, filtering and thresholds, windowed aggregations, joins and temporal event ordering, along with graph processing.
|Other cloud providers are selected. +
To embed into cloud native applications.

|Azure Stream Analytics
|To support transformations, filtering and thresholds, windowed aggregations, joins, temporal event ordering, and machine learning. +
To support stream-processing queries to run in the cloud and on the edge node.
|Other cloud providers are selected. +
To embed into cloud native applications.

|Google Dataflow
|To support transformations, filtering and thresholds, windowed aggregations, joins, temporal event ordering, and machine learning. +
To support portable stream-processing logic that can also run on on-premises stream-processing systems.
|Other cloud providers are selected. +
To embed into cloud native applications.
|===










