ifndef::imagesdir[:imagesdir: ./images]

= Data Management Patterns

== Data Composition Patterns

=== Data Service Pattern

* exposes data in the database as a service, referred to as a data service.
* The data service becomes the owner, responsible for adding and removing data from the data store. The service may perform simple lookups or even encapsulate complex operations when constructing responses for data requests.

* can also utilize caching to enhance their read performance.

Usage:

* Allow multiple microservices to access the same data

* Expose abstract legacy/proprietary data stores

image::dataService.png[Data service]

=== Composite Data Services Pattern

* performs data composition by combining data from more than one data service and, when needed, performs fairly complex aggregation to provide a richer and more concise response (Server-Side Mashup pattern)

* combines data from various services and its own data store into one composite data service

*  eliminates the need for multiple microservices to perform data composition operations, but also allows the combined data to be cached for improving performance \

*  not recommend introducing unnecessary layers of services if they do not provide meaningful data compositions that can be reused

image::compositeDataService.png[Composite Data Service]

=== Client-Side Mashup Pattern

* data is retrieved from various services and consolidated at the client side. The client is usually a browser loading data via asynchronous Ajax calls.

* uses multiple asynchronous calls to fetch different parts of the website and renders each fragment when it arrives -> *rich internet applications (RIAs)*.

Usage:

* Present critical data with low latency
* Give a perception that the web page is loading faster

image::clientSideMashup.png[Client Side Mashup]

=== Summary

|===
|Pattern	|When to use	|When not to use	Benefits

|Data Service
|Data is not owned by a single microservice, yet multiple microservices are depending on the data for their operation.
|Data can clearly be associated with an existing microservice, as introducing unnecessary microservices can also cause management complexity.
|Reduces the coupling between services. +
Provides more control/security on the operations that can be performed on the shared data.

|Composite Data Services
|Many clients query multiple services to consolidate their desired data, and this consolidation is generic enough to be reused among the clients.
|Only one client needs the consolidation. +
Operations performed by clients cannot be generalized to be reused by many clients.
|Reduces duplicate work done by the clients and consolidates it into a common service. +
Provides more data resiliency by using caches or static data.

|Client-Side Mashup
|Some meaningful operations can be performed with partial data; for example, rendering nondependent data in web browsers.
|Processing, such as a join, is required on the independently retrieved data before sending the response.
|Results in more-responsive applications. +
Reduces the wait time.
|===

== Data Scaling Patterns

=== Data Sharding Pattern

*  the data store is divided into shards, which allows it to be easily stored and retrieved at scale. The data is partitioned by one or more of its attributes so we can easily identify the shard in which it resides.

==== Horizontal data sharding

Each shard has the same schema, but contains distinct data records based on its sharding key.

* shared by hashing the order ID into three shards

image::hShard.png[H shard]

==== Vertical data sharding

* Each shard does not need to have an identical schema and can contain various data fields.
* partition the data based on the frequency of data access

image::vShard.png[V shard]

==== Functional data sharding

Data is partitioned by functional use cases. Rather than keeping all the data together, the data can be segregated in different shards based on different functionalities.

image::fShard.png[F Shard]

Horizontal sharding strategies:

* Lookup-based data sharding

A lookup service or distributed cache is used to store the mapping of the shard key and the actual location of the physical data. When retrieving the data, the client application will first check the lookup service to resolve the actual physical location for the intended shard key, and then access the data from that location. If the data gets rebalanced or resharded later, the client has to again look up the updated data location.

* Range-based data sharding

This special type of sharding approach can be applied when the sharding key has sequential characters. The data is shared in ranges, and as in lookup-based sharding, a lookup service can be used to determine where the given data range is available. This approach yields the best results for sharding keys based on date and time. A data range of a month, for example, may reside in the same shard, allowing the service to retrieve all the data in one go, rather than querying multiple shards.

* Hash-based data sharding

Constructing a shard key based on the data fields or dividing the data by date range may not always result in balanced shards. At times we need to distribute the data randomly to generate better-balanced shards. This can be done by using hash-based data sharding, which creates hashes based on the shard key and uses them to determine the shard data location. This approach is not the best when data is queried in ranges, but is ideal when individual records are queried. Here, we can also use a lookup service to store the hash key and the shard location mapping, to facilitate data loading.

=== Command and Query Responsibility Segregation Pattern

* separates updates and query operations of a data set, and allows them to run on different data stores. This results in faster data update and retrieval. It also facilitates modeling data to handle multiple use cases, achieves high scalability and security, and allows update and query models to evolve independently with minimal interactions.

image::CQRS.png[CQRS]

Usage:

* Use different domain models for command and query

For a retail website, we may be storing the product detail and inventory information in a normalized _relational database_. This might be our best choice to efficiently update inventory information upon each purchase. But this may not be the best option for querying this data via a browser, as joining and converting the data to JSON can be time-consuming. If that is the case, we can use this pattern to asynchronously build a query data set, such as a document store storing data in JSON format, and use that for querying. Then we will have separate optimized data models for both command and query operations.

* Distribute operations and reduce data contention

This pattern can be used when cloud native applications have performance-intensive update operations such as data and security validations, or message transformations, or have performance-intensive query operations containing complex joins or data mapping. When the same instance of the data store is used for both command and query, it can produce poor overall performance due to higher load on the data store. Therefore, by splitting the command and query operations, CQRS not only eliminates the impact of one on the other by improving the performance and scalability of the system, but also helps isolate operations that need higher security enforcement.

*CQRS is not recommended when high consistency is required between command and query operations*. When data is updated, the updates are sent asynchronously to the query stores via events by using patterns such as Event Sourcing. Hence, use CQRS only when eventual consistency is tolerable. Achieving high consistency with synchronous data replication is not recommended in cloud native application environments as it can cause lock contention and introduce high latencies.

=== Summary
|===
|Pattern	|When to use	|When not to use	Benefits
|Data Sharding
|Data contains one or a collection of fields that uniquely identify the data or meaningfully group the data into subsets.
|Shard key cannot produce evenly balanced shards. +
|The operations performed in the data require the whole set of data to be processed; for example, obtaining a median from the data set.
|Groups shards based on the preferred set of fields that produce the shard key. +
Creates geographically optimized shards that can be moved closer to the clients. +
Builds hierarchical shards or time-range-based shards to optimize the search time. +
Uses secondary indexes to query data by using nonshard keys.

|Command and Query Responsibility Segregation (CQRS)
|Applications have performance-intensive update operations with:

* Data validations
* Security validations
* Message transformations

For performance-intensive query operations such as complex joins or data mapping.

|High consistency is required between command (update) and query (read). +
Command and query models are closer to each other.
|Reduces the impact between command and query operations. +
Stores command and query data in two different data stores that suit their use cases. +
Enforces separated command/query security policies. +
Enables different teams to own applications that are responsible for command and query operations. +
Provides high availability.
|===

== Performance Optimization Patterns

=== Materialized View Pattern

* stores all relevant data of a service in its local data store and formats the data optimally to serve the queries

* replicates and moves data from dependent services to its local data store and builds materialized views

image::materializedView.png[Materialized view]

Usage:

* Improve data-retrieval efficiency
* Provide access to nonsensitive data hosted in secure systems

* provides resiliency. As the data is replicated to the local store, the service will be able to perform its operations without any interruption, even when the source service that provided the data is unavailable.

* do not recommend using this pattern when data can be retrieved from dependent services with low latency, when data in the dependent services is changing quickly, or when the consistency of the data is considered important for the response.

=== Data Locality Pattern

* move execution closer to the data

* adding a service dedicated to the query at the data node can improve performance by processing most of the data locally rather than transferring it over the network

* When the service cannot be moved to the same node, moving the service to the same region or data center can help better utilize the bandwidth.

image::dataLocality.png[Data Locality]

* move execution closer to the data by moving it to the data store as stored procedures

Usage:

* Reduce latency when retrieving data +
-  need to retrieve data from one or more data sources and perform some sort of join.

* Reduce bandwidth usage when retrieving data
- useful when we need to retrieve data from multiple sources to perform data aggregation or filtering operations.

=== Caching Pattern

A cache is usually an in-memory data store used to store previously processed or retrieved data so we can reuse that data.

* cache hit
* cache miss

*Read-through cache operation* - When a cache miss occurs, the system usually needs to process or fetch data from the data store, as well as update the cache with the retrieved data for future reference

*Write-through cache operation* - when a request is made to update the data, we should update it in the data store and remove or invalidate any relevant previously fetched entries stored in the cache

Eviction policy:

* least recently used (LRU) - removes data that is not used for a long period to accommodate new entries
*  first in, first out (FIFO) - removes the oldest loaded entry
* most recently used (MRU) - removes the last-used entry
* trigger-based options - remove entries based on values in the trigger event

Usage:

* Improve time to retrieve data
* Improve static content loading - Caching is best for static data or for data that is rarely updated.
* Reduce data store contention - Because it reduces the number of calls to the data store, we can use this pattern to reduce data store contention or when the store is overloaded with many concurrent requests
* Prefetch data to improve data-retrieval time
* Achieve high availability by relaxing the data store dependency - Caching can also be used to achieve high availability, especially when the service availability is more important than the consistency of the data. We can handle service calls with cached data even when the backend data store is not available. Making the local cache fall back on a shared or distributed cache, which in turn can fall back to the data store when the data is not present

image::caching.png[Caching]

* Cache more data than a single node can hold - Distributed caching systems can be used as another alternative option when the local cache or shared cache cannot contain all the needed data. They also provide scalability and resiliency by partitioning and replicating data.

The biggest disadvantage of caching data locally is that when services scale, each service will have its own local cache and will sync data with the data stores at different times. +
By invalidating all the caches during data updates by either informing the cache nodes about the update via a messaging system, as in the Publisher-Subscriber pattern, or by using the Event Sourcing pattern.

* implementing *forceful expiry or reload of the cache*. For instance, if the client is aware of a potential update through other means, we can let the client forcefully reload the cache before retrieving data. We can achieve this by introducing a random variable as part of the cache key when storing the data. The client can use the same key over and over again, and change it only when needing to force a reload.

=== Static Content Hosting Pattern

* eploys static content in data stores that are closer to clients so content can be delivered directly to the client with low latency and without consuming excess computational resources.

* allows us to directly serve static content from storage services such as content delivery networks (CDNs).

image::cdn.png[CDN]

=== Summary
|===
|Pattern	|When to use	|When not to use	Benefits
|Materialized View
|Part of the data is available locally, and the rest of the data needs to be fetched from external sources that incur high latency. +
The data that needs to be moved is small and rarely updated. +
Provides access to nonsensitive data that is hosted in secure systems.
|Data can be retrieved from dependent services with low latency. +
Data in the dependent services is changing quickly.+
Consistency of the data is considered important for the response.
|Can store the data in any database that is suitable for the application. +
Increases resiliency of the service by replicating the data to local stores.

|Data Locality
|To read data from multiple data sources and perform a join or data aggregation in memory. +
The data stores are huge, and the clients are geographically distributed.
|Queries output most of their input. +
Additional execution cost incurred at the data nodes is higher than the cost of data transfer over the network.
|Reduces network bandwidth utilization and data-retrieval latency. +
Better utilizes CPU resources and optimizes overall performance. +
Caches results and serves requests more efficiently.

|Caching
|Best for static data or data that is read more frequently than it is updated. +
Application has the same query that can be repeatedly called multiple times by one or more clients, especially when we do not have enough knowledge about what data will be queried next. +
The data store is subject to a high level of contention or cannot handle the number of concurrent requests it is receiving from multiple clients.
|The data is updated frequently. +
As the means of storing state, as it should not be considered as the single source of truth. +
The data is critical, and the system cannot tolerate data inconsistencies.
|Can choose which part of the data to cache to improve performance. +
Using a cache aside improves performance by reducing redundant computations. +
Can preload static data into the cache. +
Combined with eviction policy, the cache can hold the recent/required data.

|Static Content Hosting
|All or some of the data requested by the client is static. +
The static data needs to be available in multiple environments or geographic locations.
|The static content needs to be updated before delivering to the clients, such as adding the access time and location. +
The amount of data that needs to be served is small. +
Clients cannot retrieve and combine static and dynamic content together.
|Geographically partitioning and storing closer to clients provides shorter response times and faster access/download speed. +
Reduces resource utilization on rendering services.
|===







