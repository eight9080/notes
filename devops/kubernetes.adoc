ifndef::imagesdir[:imagesdir: ../images]
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
= Kubernetes

== Core concepts

Kubernetes, K8s, is an open‑source system for automating deployment, scaling, and management of containerized applications.

* management of the containers, eliminate single points of failure in our application, scale containers easily, and update containers without actually even bringing down the running application

* robust networking infrastructure so that containers can talk to other containers, even across different machines.

* some storage options across machines

=== Key features
* Service discovery/ Load balancing
* Storage orchestration
* Automate Rollouts/Rollbacks - a zero downtime deployment
* Self-healing
* Secret and configuration management - ConfigMaps can be used to store key value pairs
* Horizontal scaling

Kubernetes provides a declared way to define a *cluster's state*
Current state -> desired state

One or more master nodes -> it will call worker nodes. +
The worker nodes can be physical servers/ virtual machines.(they will form a cluster). +
A node is just a virtual machine, and it can run one or more pods.

The master will start on each of these nodes -> *pods*.

A pod - a way to host a container, the packaging.

Deployments and replica sets - a way to deploy the pods.

Services - to enable pods to communicate possibly with the outside world or just amongst themselves within the cluster.

On master:

*etcd store* on our master nodes - the database for everything the master node needs to track.

A *Controller manager* - responsible for when a request comes in, the manager can act upon that request and schedule it using a *scheduler*

*The scheduler* will determine when the nodes and the different pods running on the nodes actually come to life or go away.

To interact with the master to give it instructions to go from one state to another by using a command line tool called *kubectl*
Kubectl is just making your different types of RESTful service calls to send these before and after state requests to the master.

image::kubernetes/kubernetesMaster.png[Kubernetes master]

On each node:

* a little agent installed and running on each node that registers that node with the cluster and reports back and forth to the manager. That's called the *kubelet*

* container runtime - to run our containers within the pods

* networking capabilities - a *kube‑proxy* that can ensure that each pod gets a unique IP address

image::kubernetes/kubernetesNodes.png[Kubernetes node]

==== Benefits

* Accelerate Developer Onboarding
* Eliminate App Conflicts
* Environment Consistency
* Ship Software faster

* Orchestrate containers
* Zero-Downtime Deployments
* Self Healing - desired state
* Scale containers ( add more pods )

Developer Use Case:

* Emulate production locally
* Create an end-to-end testing environment
* Ensure application scales properly
* Ensure secrets/config are working properly
* Performance testing scenarios
* Workload scenarios (CI/CD)

== Running Kubernetes Locally

* Minikube
* Docker Desktop

=== kubectl

Basic commands:

* Check Kubernetes version
----
kubectl version
----
* View cluster information
----
kubectl cluster-info
----
* Retrieve information about Pods, Deployments, Services..
----
kubectl get all
----
* Simple way to create a deployment for a Pod
----
kubectl run [container-name] --image=[image-name]
----
* Forward a port to allow external access
----
kubectl port-forward [pod] [pors]
----
* Expose a port for a Deployment/Pod
----
kubectl expose
----
* Create a resource
----
kubectl create [resource]
----
* Create or modify a resource
----
kubectl apply [resource]
----

=== Web UI Dashboard
----
kubectl apply dashboard-yaml-url
kubectl describe secret -n kube-system
kubectl proxy
----

== Pods
*A pod is a group of one or more containers, with shared storage/network, and a specification for how to run the containers.*

A Pod is the basic execution unit of a Kubernetes application, the smallest and simplest unit in the Kubernetes object model that you create or deploy. +
Pods act as an environment for containers.

NOTE: A single process per container, and oftentimes *a single container per Pod*

.Characteristics
****
* A Pod has an IP address, memory, volumes, and all of that can be shared across multiple containers within the Pod if needed.
* Pods within a node are going to have a unique IP address, ** cluster IP address**, and then the containers within Pods can then have their own unique ports. +
* Pod containers share the same network namespace, they share the same IP.
* They use the same loopback network interface within a Pod -> localhost
* Now containers processed within the same Pod need to have a different port.

Multiple containers within a Pod -> a container and then another one is very tightly coupled -> *sidecar container*
****

[IMPORTANT]
====
* So if Kubernetes sees a Pod that's unhealthy or sick, it can automatically remove that and then replace it. +
*  Pods can be horizontally scaled. -> replicas - Kubernetes can load balance between those +
* Kubernetes will monitor that and can automatically take it out and then put something back that's a healthy Pod.
====


=== Creating a Pod

Different ways:

* kubectl run command
* kubectl create/apply command with a yaml file

-> create a deployment behind the scenes for deploying that pod and scheduling it on the appropriate node within your Kubernetes cluster

----
kubectl run [podname] --imagine=nginx:alpine
----

==== Get info about the pods
----
kubectl get pods
kubectl get all
----

==== Expose a Pod Port
Pods and containers are only accessible within the Kubernetes cluster by default.
One way to expose port externally: `external port: internal port`
----
kubectl port-forward [name-of-pod] 8080:80
----

==== Delete a pod

Running a Pod will cause a deployment to be created.
To delete a Pod use kubectl delete pod or find the deployment and use kubectl delete deployment.

----
kubectl delete pod [name-of-pod]
----

Delete the Deployment that manages the pod

----
kubectl delete deployment [name-of-deploymet]
----

_A deployment is responsible for making sure that the current state is maintained._

==== Defining a Pod with YAML

Basic file
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
 name: my-nginx
spec:
 containers:
 - name: my-nginx
   image: nginx:alpine
----

To create a pod using YAML use kubectl create command along with the --filename or -f switch
----
kubectl create -f file.pod.yml --dry-run --validate=true
kubectl create -f file.pod.yml
----

To create or apply changes to a pod using YAML kubectl apply
----
kubectl apply -f file.pod.yml
----

To delete a node using YAML:
----
kubectl delete -f file.pod.yml
----

Describe pod
----
kubectl describe pod [pod-name]
----

Exec commands into the container of the pod
----
kubectl exec [pod-name] -it sh
----

=== Pod health

Kubernetes relies on *probes* to determine the health of a pod container. A probe is a diagnostic performed periodically by the kubelet on a container.

Types of probes:

* Liveness probe - used to determine the health of the pod
* Readiness probe - helps Kubernetes determine when it should start sending requests

If the container in the pod, though, fails one of these health checks, then it can be restarted. And there's a restart policy that defaults to always.

It could run a command, for example, and as long as it returns zero, then that's successful.
Perform a TCP type of check on the IP address of a port and see if that's successful.

Liveness probe example
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: liveness-request
spec:
  containers:
  - name: liveness
    image: nginx:alpine
    ports:
        - containerPort: 80
    livenessProbe:
      httpGet:
        path: /index.html
        port: 80
      initialDelaySeconds: 15 #Default 0
      timeoutSeconds: 2 #Default 1
      periodSeconds: 5 #Default 10 Check every 5 seconds
      successThreshold: 1 #Default 1
      failureThreshold: 1 #Default 3 Allow 1 failure before failing Pod
----


Readiness probe example
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: readiness-request
spec:
  containers:
  - name: readiness
    image: nginx:alpine
    ports:
        - containerPort: 80
    readinessProbe:
      httpGet:
        path: /index.html
        port: 80
      initialDelaySeconds: 2 #Default 0
      periodSeconds: 5 #Default 10 Check every 5 seconds
----

== Deployments

A *ReplicaSet* is a declarative way to manage Pods. +

NOTE: A Replica Set ensures that a specified number of pod replicas are running at any one time. In other words, a Replica Set makes sure that a pod or a homogeneous set of pods is always up and available.

A *Deployment* is a declarative way to manage Pods using a ReplicaSet.

[NOTE]
====
A Deployment controller provides declarative updates for Pods and ReplicaSets.

* describe a desired state in a Deployment object, and the Deployment controller changes the actual state to the desired state at a controlled rate.
* can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
* include Pod(s) and Replica Set.
* to update the resources when you deploy new version.
====

Deployment and ReplicaSets ensure Pods stay running and can be used to scale Pods.

ReplicaSets act as a Pod Controller:

* self-healing mechanism
* ensure the requested number of Pods are available
* provide fault-tolerance
* can be used to scale Pods
* relies on a Pod template
* used by deployments

A Deployment manages Pods:

* Pods are managed using ReplicaSets
* Scales ReplicaSets
* Support zero-downtime updates by creating and destroying ReplicaSets
* Provides rollback functionality
* Creates a unique label that is assigned to the ReplicaSet and generated Pods

Example:
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
----

Commands deployment:
----
kubectl create -f file.deployment.yml
kubectl apply -f file.deployment.yml
kubectl get deployments
kubectl get deployments --show-labels
kubectl get deployments -l app=nginx
kubectl delete deployment [deployment-name]

kubectl scale deployment [deployment-name] --replicas=5
kubectl scale -f file.deployment.yml --replicas=5
----

== Services

A Service provides a single point of entry for accessing one or more Pods and is *an abstraction which defines a logical set of Pods and a policy by which to access them*

Roles:

* Services abstract Pod IP addresses from consumers
* Load balances between Pods
* Relies on labels to associate a Service with a Pod
* Node's kube-proxy creates a virtual IP for Services
* Services are not ephemeral
* Creates endpoints

=== Service Types

* Cluster IP - expose the service on a cluster-internal IP (default) +
Only Pods within the cluster can talk to the service. By having a single IP address it enables the service to be load balanced across multiple Pods.

* NodePort -  Expose the service on each Node's IP at a static port +
External caller can call the service. Each Node proxies the allocated port.

* Load Balancer - provision an external IP to act as a load balancer for the service +
Exposes a Service externally. +
NodePort and ClusterIP Services are created.

* ExternalName - Maps a service to a DNS name +
service that acts as an alias for an external service.

[source,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
    - name: http
      port: 80
      targetPort: 80
----

Name of Services -> each service gets a DNS entry
`backend:port`

----
kubectl create -f file.service.yml
kubectl apply -f file.service.yml
kubectl get service
kubectl get service --show-labels
kubectl get service -l app=nginx
kubectl delete service [service-name]

kubectl exec [pod-name] -- curl -s http://podIP
----

=== Ingress

Ingress exposes HTTP and HTTPS *routes from outside the cluster to services* within the cluster. Traffic routing is controlled by rules defined on the Ingress resource.

[NOTE]
====
* Ingress enables externally-reachable urls, load balance traffic, terminate SSL, offer name based virtual hosting for a Kubernetes cluster.
* Ingress rules can be based on a request host (domain), or the path of the request, or a combination of both
* is a collection of routing rules that govern how external users access services running in a Kubernetes cluster.
====

























