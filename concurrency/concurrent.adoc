ifndef::imagesdir[:imagesdir: ./imagesC]
= Concurrent programming

== General

Stack of layers:

* Application
* AdditionalFrameworks and Languages
* Threading and synchronization packages
* Java Virtual Machine (JNI) - Thread Scheduler
* System Libraries
* Operation System Kernel

== Thread

A thread is defined at the operating system level. +
A thread is a set of instructions. +

Java offers two types of threads: user threads and daemon threads.

*User threads* are high-priority threads. The JVM will wait for any user thread to complete its task before terminating it.

*Daemon threads* are low-priority threads whose only role is to provide services to user threads.

The JVM itself, the Java Virtual Machine, works with several threads:

- There are threads for the garbage collection.
- There are threads for the Just In Time compiler
- other technical threads.

A CPU with only one core -> this CPU can only do one thing at a time. +
If I have only one core, nothing is really happening at the same time.
All those little actions are just happening so fast, that it feels they are happening at the same time.

CPU with two cores. +
CPU is able to do two things at the same time. +

On a multi-core CPU, things are really happening at the same time. +
CPU is able to run several tasks at the same time.

=== CPU Time Sharing Using a Thread Scheduler

A thread-scheduler is going to share evenly, the CPU timeline, divided into time slices, to all the tasks that need to be run.

There are three reasons for the scheduler to pause a thread, and to run another thread:

-  the CPU resource should be shared equally among the threads (check priority)
- A thread might be waiting for some more data. (some input output, reading or writing data to a disk or to a network)
- a thread might be waiting for another thread to do something. (to release a resource)

=== Race condition

A race condition deals with the *access of data concurrently*.

Two different threads are trying to read and write the same variable or the same field, at the same time.

==== Singleton pattern

[source,java]
----
public class Singleton{
    private static Singleton instance;
    private Singleton() {}

    public static Singleton getInstance(){
        if(instance==null){
            instance = new Singleton();
        }
        return  instance;
    }
}
----

- not a good implementation, not thread safe

To prevent this -> Synchonization

== Synchronization

Synchronization prevents a block of code to be executed by more than one thread at the same time. +
From a technical point of view -> it will prevent the *thread scheduler* to give the hand to a thread that wants to execute the synchronized portion of code that has already been executed by another thread.

[source,java]
----
public class Singleton{
    private static Singleton instance;
    private Singleton() {}

    public static synchronized Singleton getInstance(){
        if(instance==null){
            instance = new Singleton();
        }
        return  instance;
    }
}
----

=== Under the hood

The singleton class is a class with a get instance method that we want to synchronize.

The Java machine uses a special object, called a *lock object*, that has a key. The lock object has only one single key.

 A. When a thread want to enter this protected method, this protected block of code, it will make a request on this lock object, give me your key.
  * If the lock object has the key available, it will give it to this thread, and this thread will be able to run the get instance method freely.
 B. If another thread wants to enter this synchronized block of code, it will make the same request on the lock object, but this time, the lock object has no key available for him.

==== Lock Object

*Lock* (monitor) - A special technical object that will hold the key. This key is defined internally in the object class. _Every Java object can play this role._

The synchronized keyword on a public static method of the singleton class -> the JVM uses the *singleton class object itself*. +
_All the classes in Java are represented by objects._

* synchronized static method -> the object chosen to hold the key is the *class object itself*.
* on a non-static method -> the instance of the class

* to use a dedicated, explicit object to conduct synchronization
private final object called key, synchronized block inside this method, pass this key object as a parameter of this synchronized keyword.

[source,java]
----
public class Person {
    private final Object key = new Object();

    public String init(){
        synchronized(key){
            // stuff
        }
    }
}
----

===== Rules

* Two threads can execute concurrently a synchronized static method and a non-static method of the same class. The threads acquire locks on different objects.

* Two threads cannot concurrently execute two different synchronized static methods (or the same synchronized static method) of the same class.
The first thread acquires a class-level lock.

* Two threads can concurrently execute non-synchronized, synchronized static, and synchronized non-static methods

==== Multiple synchronized methods

[source,java]
----
public class Person {
    public synchronized String getName(){
        return "1";
    }

    public synchronized int getAge(){
        return 10;
    }
    public static create(){
        Person marry = new Person();
    }
}
----

If a thread wants to execute getName -> it will take the *key* from the lock object, thus preventing a red thread from executing getAge at the same time. -> the same key is used to synchronize both methods.

If we need to synchronize getName *independently* of getAge, then two lock objects in the person class need to be created, and synchronize the block of codes inside the methods on those two different objects.

Using the synchronized keyword on a method declaration, uses an implicit lock object, which is the class object in the case of a static method, or the instance object itself in the case of a non-static method.

If what we really want is to prevent two threads to execute the getName method at the same time, in all the instances of the person class, then we need our lock object to be bound not to each instance of our class, but to the class itself -> _the static field of the class person itself_

=== Reentrant Lock

*Locks are reentrant* -  When a thread holds a lock, it can enter a block synchronized on the lock it is holding. (inheritance)

=== Deadlock

Mary and John instances of the person class, a synchronized method that is calling another synchronized method. +
First method is synchronized using a red key, and the method called by this method is synchronised using a green key. This green protected method calls another method, the third one, protected also by the red key. The blue thread is going to take the red key, and begin to run this first method. And at the same time, the purple thread is going to take the green key, and to run the other method. At some point, the blue thread will need the green key to enter the green method, but the purple thread has it. So this blue thread has to wait. And the purple thread will arrive at the point of code where it needs the red key to continue to run. And unfortunately the red key is not available, because it is held by the blue thread.

*A deadlock situation is a situation where a thread T one holds a key that is needed by another thread T two. And the deadlock is the fact that T two also holds the key needed by T one. So as long as no thread releases its key, the situation is blocked, and called a deadlock.*

== Runnable Pattern to Launch Threads

Small Example

[source, java]
----
public class FirstRunnable {

	public static void main(String[] args) {

		Runnable runnable = () -> {
			System.out.println("I am running in " + Thread.currentThread().getName());
		};

		Thread t = new Thread(runnable);
		t.setName("My thread");

		t.start();
	}
}
----

== Implementing the Producer/Consumer Pattern Using Wait / Notify

=== Runnable Pattern

[source, java]
----
@FunctionalInterface
public interface Runnable {
    void run();
}
----

The `Thread.currentThread()` static method returns the current thread.

==== How to Stop a Thread Using the interrupt() Method

* not using `stop()` method - never

* using `interrupt` method -  send a signal to the task the thread is running telling it that it is time for this task to stop itself.

----
Runnable task = () -> {
    while (!Thread.currentThread().isInterrupted()){
        // the task
    }
}
----

* calling `interrupt` will cause the isInterrupted method to return true

_If the thread is blocked or waiting, then the corresponding method will throw an interrupted exception._

=== Implementing a First Producer/Consumer Example

Producer/Consumer:

* A producer produces values in a buffer
* A consumer consumes the values from this buffer

Producers/consumers are run in their own thread.

[source,java]
----
public class ProducerConsumer {
	private static int count;
    private static int[] buffer = new int[BUFFER_SIZE];

	static class Producer {
		void produce() {
				while (isFull(buffer)) {}
				buffer[count++] = 1;
		}
	}

	static class Consumer {

		void consume() {
			while (isEmpty(buffer)) {}
			buffer[--count] = 0;
		}
	}

	static boolean isFull(int[] buffer) {
		return count == buffer.length;
	}
	static boolean isEmpty(int[] buffer) {
		return count == 0;
	}
}
----

==== 1. Synchronized Version of the Producer / Consumer

- synchronize access to array
- synchronize a common object that will be used by the Producer/consumer

[source,java]
----
public class ProducerConsumer {

	private static Object lock = new Object();

	private static int[] buffer;
	private static int count;

	static class Producer {

		void produce() {
			synchronized (lock) {
				while (isFull(buffer)) {}
				buffer[count++] = 1;
			}
		}
	}


	static class Consumer {

		void consume() {
			synchronized (lock) {
               while (isEmpty(buffer)) {}
               buffer[--count] = 0;
			}
		}
	}

	static boolean isEmpty(int[] buffer) {
		return count == 0;
	}

	static boolean isFull(int[] buffer) {
		return count == buffer.length;
	}
}
----

==== 2. Synchronized Version of the Producer / Consumer

What if the buffer is empty -> the thread executing this consumer is blocked in the while loop.
So the producer has no chance to add objects to the buffer.

* need to park a thread while he is waiting for some data to be produced, without blocking all the others threads.
* so the key/monitor should be released while this thread is waiting

=== wait() and notify() Methods

* methods from the Object class
* invoked on a given object, the thread executing the invocation should hold the key of that object

If the thread that is executing a wait method does not hold the key of the object on which it is executing this method, then an exception is raised -> _the only way for a thread to hold the key of an object is to be in a synchronized block_

* *wait and notify cannot be invoked outside a synchronized block*

1. calling the wait on a lock object releases the key held by the thread
  a. this key becomes available to the other thread
  b. it puts the current thread in a particular state called the WAIT state
The only way to release a thread from a WAIT state is to call notify on the lock object this thread is using.

2. calling notify released a thread that is in a WAIT state so a thread that has called a wait method and it puts it in the Runnable state. -> the only way to release a waiting thread

If there are more than one thread in the WAIT state, the released thread by the notify method is chosen randomly among those threads.
* a notifyALL method -> will awake all the threads in the WAIT state.

==== implementation with wait/notify

[source,java]
----
package org.paumard.waitnotify;

public class ProducerConsumer {

	private static Object lock = new Object();

	private static int[] buffer;
	private static int count;

	static class Producer {

		void produce() {
			synchronized (lock) {
				if (isFull(buffer)) {
					try {
						lock.wait();
					} catch (InterruptedException e) {
						e.printStackTrace();
					}
				}
				buffer[count++] = 1;
				lock.notify();
			}
		}
	}


	static class Consumer {

		void consume() {
			synchronized (lock) {
				if (isEmpty(buffer)) {
					try {
						lock.wait();
					} catch (InterruptedException e) {
						e.printStackTrace();
					}
				}
				buffer[--count] = 0;
				lock.notify();
			}
		}
	}

	static boolean isEmpty(int[] buffer) {
		return count == 0;
	}

	static boolean isFull(int[] buffer) {
		return count == buffer.length;
	}

	public static void main(String... strings) throws InterruptedException {

		buffer = new int[10];
		count = 0;

		Producer producer = new Producer();
		Consumer consumer = new Consumer();

		Runnable produceTask = () -> {
			for (int i = 0 ; i < 50 ; i++) {
				producer.produce();
			}
			System.out.println("Done producing");
		};
		Runnable consumeTask = () -> {
			for (int i = 0 ; i < 45 ; i++) {
				consumer.consume();
			}
			System.out.println("Done consuming");
		};

		Thread consumerThread = new Thread(consumeTask);
		Thread producerThread = new Thread(produceTask);

		consumerThread.start();
		producerThread.start();

		consumerThread.join();
		producerThread.join();

		System.out.println("Data in the buffer: " + count);
	}
}

----

== States of a Thread

* New - when a thread is created new Thread()
* Runnable - once the start method was invoked it is eligible to be run
* Terminated - once the task is completed
* Blocked - waiting at the entrance of a synchronized block (When a thread is trying to execute I/O tasks or synchronized blocks)
* Waiting - parked using a wait call (A thread, t1, that waits (without a timeout period) for another thread, t2, to finish)
* Timed_waiting - parked using a sleep(timeout) or wait(timeout) call

The thread scheduler can run the threads in the state RUNNABLE. +
A BLOCKED thread can only run again when the key is released. +
A WAITING thread can only run again when the notify() method is called.

Getting the state `thread.getState()`

image::threadLifeCycle.png[Thread lifecycle]

=== The Scheduler
Access to the CPU is controlled by the process scheduler. This uses a queue known as the *run queue as a waiting area* for threads or processes that are eligible to run but which must wait their turn for the CPU. +
The job of the scheduler is to respond to interrupts, and to manage access to the CPU cores.

The OS scheduler moves threads on and off the single core in the system. +
At the end of the time quantum (often 10 ms or 100 ms in older operating systems), the scheduler moves the thread to the back of the run queue to wait until it reaches the front of the queue and is eligible to run again.

==== Context Switches

A context switch is the process by which the OS scheduler removes a currently running thread or task and replaces it with one that is waiting.

A context switch can be a costly operation, whether between user threads or from user mode into kernel mode (sometimes called a mode switch).

== Ordering Read/Write

Synchronization

* protects a block of code
* guarantees this code is executed by one thread at a time
* prevents race condition

=== Memory access

A CPU does not read a variable from main memory, but from a cache. +
A CPU has multiple cores. +
Each CPU has a L1 and L2 cache. L3 cache is common for all cores. +

Access to the:

* main memory ~100ns
* L2 cache 7ns
* L1 cache 0.5ns

Size L2 Cache 256 kB  - Size L1 cache 32 kB

Visibility:

* A variable is said to be visible if *the writes made on it are visible*
* All the synchronized writes are visible

=== Before link

A happens before link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow.

All shared variables should be accessed in a synchronized or a volatile way.

=== False sharing

Memory is stored within the cache system in units know as cache lines.  Cache lines are a power of 2 of contiguous bytes which are typically 32-256 in size.

False sharing is a term which applies when threads unwittingly impact the performance of each other while modifying independent variables sharing the same cache line.

To achieve linear scalability with number of threads, we must ensure no two threads write to the same variable or cache line.  Two threads writing to the same variable can be tracked down at a code level.   To be able to know if independent variables share the same cache line we need to know the memory layout, or we can get a tool to tell us.

==== Java Memory Layout

For the Hotspot JVM, all objects have a 2-word header.

First is the “mark” word which is made up of 24-bits for the hash code and 8-bits for flags such as the lock state, or it can be swapped for lock objects.

The second is a reference to the class of the object.

Arrays have an additional word for the size of the array.  Every object is aligned to an 8-byte granularity boundary for performance.

* doubles (8) and longs (8)
* ints (4) and floats (4)
* shorts (2) and chars (2)
* booleans (1) and bytes (1)
* references (4/8)

[source, java]
----
public final static class VolatileLongPadded {
		public long q1, q2, q3, q4, q5, q6 ;
		public volatile long value = 0L;
		public long q11, q12, q13, q14, q15, q16 ;

	}
----

== Singleton Pattern

Do not use synchronized

[source, java]
----
public class Singleton {
    private static Singleton instance;
    private Singleton() {}

    public static synchronized Singleton getInstance() {
        if (instance == null){
            instance = new Singleton();
        }
        return instance;
    }
}
----


Do not use Double Check Locking
[source, java]
----
public class Singleton {
    private static Singleton instance;
    private static Object key = new Object();
    private Singleton() {}

    public static Singleton getInstance() {
        if (instance != null){
            return instance;
        }
        synchronized (key){
            if (instance == null){
                instance = new Singleton();
            }
            return instance;
        }
    }
}
----

Double Check Locking - fixed with volatile

[source, java]
----
public class Singleton {
    private static volatile Singleton instance;
    private Singleton() {}

    public static Singleton getInstance() {
        if (instance != null){
            return instance;
        }
        synchronized (Singleton.class){
            if (instance == null){
                instance = new Singleton();
            }
            return instance;
        }
    }
}
----

The right solution
[source, java]
----
public enum Singleton {
    INSTANCE
}
----

== Volatile

* ensures that changes to a variable are always consistent and visible to other threads atomically
* volatile is not needed in sequential programs
* a value written to a volatile variable will always be stored in main memory.
* access to a volatile variable will be read from main memory


== Java 8 concurrency
=== Parallel Streams

A parallel stream partitions a stream into multiple substreams that run concurrently & combine into a reduced result. +
Aggregate operations in a parallel stream can be mapped to multiple cores.

*ForkJoinPool size defaults to the number of cores available to the JVM*



=== Completable Futures
It supports dependent functions that trigger upon completion of asynchronous operations.





